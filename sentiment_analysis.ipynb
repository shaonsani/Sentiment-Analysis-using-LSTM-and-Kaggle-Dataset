{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOU07YOn1QU0DpoAxS80AiG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaonsani/Sentiment-Analysis-using-LSTM-and-Kaggle-Dataset/blob/master/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh2F-lPjFGJJ"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0NDRNWRd7Cj",
        "outputId": "deed8a53-57f1-4793-8803-10610f1008af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "data = pd.read_csv('Tweets.csv',sep=',')\n",
        "data.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[2 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL9o0m2yfRFX"
      },
      "source": [
        "tweet_df = data[['text','airline_sentiment']]\n",
        "tweet_df = tweet_df[tweet_df['airline_sentiment']!='neutral']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWFOl-HFhFcw"
      },
      "source": [
        "sentiment_label = tweet_df.airline_sentiment.factorize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqmMebROqHHX"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "tweet = tweet_df.text.values \n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(tweet)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index)+1\n",
        "encoded_docs = tokenizer.texts_to_sequences(tweet)\n",
        "padded_sequences = pad_sequences(encoded_docs,maxlen=200)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYryzoRgPMr0",
        "outputId": "c1da64cd-dc64-4112-eec7-9c96a64c1be0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "print(encoded_docs[0])\n",
        "print(padded_sequences[77])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 340, 400, 500, 987, 1, 4, 112, 988]\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    2  189  122  721\n",
            " 1151   52    6  670   18    6  722 1152   12  716  187  196   19    6\n",
            "  506  721 1153   70]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9pe0oViQd_N",
        "outputId": "536ac2bd-22e1-4d74-e972-8721358779cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM,Dropout, SpatialDropout1D, Embedding\n",
        "\n",
        "embedding_vector_lenght=32\n",
        "model =Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_vector_lenght, input_length=200))\n",
        "model.add(SpatialDropout1D(0.25))\n",
        "model.add(LSTM(100,dropout=0.5, recurrent_dropout=0.5))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 200, 32)           76608     \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 200, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 129,909\n",
            "Trainable params: 129,909\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn-kK5XseJHz",
        "outputId": "e327b668-24cf-4589-c87f-e920fc44bbfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "history = model.fit(padded_sequences,sentiment_label[0],validation_split=0.2,epochs=20, batch_size=32)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 12s 722ms/step - loss: 0.6726 - accuracy: 0.6267 - val_loss: 0.4261 - val_accuracy: 0.8492\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 11s 700ms/step - loss: 0.6329 - accuracy: 0.6647 - val_loss: 0.5466 - val_accuracy: 0.8651\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 11s 696ms/step - loss: 0.5684 - accuracy: 0.7265 - val_loss: 0.5475 - val_accuracy: 0.7460\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 11s 693ms/step - loss: 0.4857 - accuracy: 0.7685 - val_loss: 0.4450 - val_accuracy: 0.8016\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 12s 719ms/step - loss: 0.3791 - accuracy: 0.8363 - val_loss: 0.4642 - val_accuracy: 0.8492\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 11s 686ms/step - loss: 0.3275 - accuracy: 0.8623 - val_loss: 0.4792 - val_accuracy: 0.8333\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 11s 692ms/step - loss: 0.2518 - accuracy: 0.9142 - val_loss: 0.4469 - val_accuracy: 0.7937\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 11s 708ms/step - loss: 0.1855 - accuracy: 0.9421 - val_loss: 0.4874 - val_accuracy: 0.8889\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 11s 708ms/step - loss: 0.2084 - accuracy: 0.9541 - val_loss: 0.4680 - val_accuracy: 0.8889\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 11s 709ms/step - loss: 0.1255 - accuracy: 0.9681 - val_loss: 0.4841 - val_accuracy: 0.7540\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 11s 707ms/step - loss: 0.0997 - accuracy: 0.9721 - val_loss: 0.3986 - val_accuracy: 0.8730\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 11s 706ms/step - loss: 0.0821 - accuracy: 0.9800 - val_loss: 0.4018 - val_accuracy: 0.8968\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 12s 731ms/step - loss: 0.0503 - accuracy: 0.9860 - val_loss: 0.3487 - val_accuracy: 0.8810\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 12s 720ms/step - loss: 0.0702 - accuracy: 0.9820 - val_loss: 0.3669 - val_accuracy: 0.8968\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 11s 707ms/step - loss: 0.0390 - accuracy: 0.9900 - val_loss: 0.3890 - val_accuracy: 0.8810\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 11s 717ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 0.4211 - val_accuracy: 0.8889\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 11s 713ms/step - loss: 0.0269 - accuracy: 0.9940 - val_loss: 0.3892 - val_accuracy: 0.8810\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 12s 724ms/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.4068 - val_accuracy: 0.8730\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 11s 714ms/step - loss: 0.0198 - accuracy: 0.9960 - val_loss: 0.4341 - val_accuracy: 0.8810\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 12s 728ms/step - loss: 0.0194 - accuracy: 0.9980 - val_loss: 0.4686 - val_accuracy: 0.8651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj7-JBiCiVpX",
        "outputId": "c880ff24-0d6e-4331-b8bc-0389432b5f2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_text = 'the product is fabulous'\n",
        "tw = tokenizer.texts_to_sequences([test_text])\n",
        "pw = pad_sequences(tw, maxlen=200)\n",
        "prediction = int(model.predict(pw).round())\n",
        "sentiment_label[1][prediction]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'positive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}